{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from supabase import Client, create_client\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from time import sleep\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "url = os.getenv('SUPABASE_URL')\n",
    "key = os.getenv('SUPABASE_KEY')\n",
    "\n",
    "supabase = create_client(url, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium was used here because the poem content is **server-side rendering using Javascript into HTML**. Thus, Beutiful Soup can't grab the poem data since the process was *asynchronous*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "showAllPoemUrl = \"https://www.poemhunter.com/explore/poems/lang-english/{page_number}/\"\n",
    "showPoemUrl = \"https://www.poemhunter.com{poem_url}\"\n",
    "\n",
    "def writeFile(fileName, payload, permission=\"w\"):\n",
    "    txt_url = f\"./{fileName}.txt\"\n",
    "    with open(txt_url, permission) as file:\n",
    "        file.write(f\"{payload}\\n\")\n",
    "\n",
    "def getPoemLink(minPage=1, maxPage=151, save=True):\n",
    "    poemLinks = []\n",
    "    targetClasses = {\"phBoxContinue\", \"txtc\", \"purpleLink\"}\n",
    "    for i in range(minPage,maxPage):\n",
    "        url = showAllPoemUrl.format(page_number=i)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {i}\")\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        matchingDivs = soup.find_all(\"div\", class_=lambda classList: classList and targetClasses.issubset(set(classList.split())))\n",
    "        for div in matchingDivs:\n",
    "            anchor = div.find(\"a\")\n",
    "            if anchor and \"href\" in anchor.attrs:\n",
    "                poemLinks.append(anchor[\"href\"])\n",
    "    if save:\n",
    "        filePath = f\"poem_links.json\"\n",
    "        with open(filePath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(poemLinks, f)\n",
    "        return poemLinks\n",
    "    else:\n",
    "        return poemLinks\n",
    "\n",
    "def scrapePoem(name=\"\", i=1, start=0, custom=False, customLists=[]):\n",
    "    prefs = {\n",
    "        \"profile.managed_default_content_settings.images\": 2,\n",
    "        \"profile.managed_default_content_settings.media_stream\": 2,\n",
    "    }\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-software-rasterizer\")\n",
    "    chrome_options.add_argument(\"--ignore-certificate-errors\")\n",
    "    chrome_options.add_argument(\"--ignore-ssl-errors\")\n",
    "    chrome_options.add_argument(\"--disable-setuid-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-machine-learning-model-download\")\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    service = Service(r\"./chromedriver\")\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    COBA_LAGI = 5\n",
    "    \n",
    "    with open(f\"poem_links{name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        poemsUrl = json.load(f)\n",
    "        \n",
    "    if custom:\n",
    "        poemsUrl = [poemsUrl[customList] for customList in customLists]\n",
    "        start = 0\n",
    "    \n",
    "    for idx, poem_url in enumerate(poemsUrl[start:3]): #====\n",
    "        for coba in range(COBA_LAGI):\n",
    "            try:\n",
    "                print(f\"Scrape {poem_url} index ke-{start+idx}\")\n",
    "                writeFile(\"log\", f\"Scrape {poem_url} index ke-{start+idx}\", permission=\"w\")\n",
    "                url = showPoemUrl.format(poem_url=poem_url)\n",
    "                driver.get(url)\n",
    "                \n",
    "                author = driver.find_elements(By.CSS_SELECTOR, \"div.phpdAuthor\")[0].text\n",
    "                title = driver.find_elements(By.CSS_SELECTOR, \"div.phPageDetailsTitle\")[0].text\n",
    "                poem_data = driver.find_elements(By.CSS_SELECTOR, \"div.phContent.phcText\")[0].text\n",
    "                date_created = driver.find_elements(By.CSS_SELECTOR, \"div.phPageDate\")[0].text\n",
    "                rating = driver.find_elements(By.CSS_SELECTOR, \"div.phRate > span.rate\")[0].text\n",
    "                date_scraped = datetime.now().date().isoformat()\n",
    "                \n",
    "                # print('URL =', url, type(url))\n",
    "                # print('AUTHOR =', author, type(author))\n",
    "                # print('TITLE =', title, type(title))\n",
    "                # print('POEM DATA =', poem_data, type(poem_data))\n",
    "                # print('DATECREATED =', date_created, type(date_created))\n",
    "                # print('RATING =', rating, type(rating))\n",
    "                # print('DATESCRAPED =', date_scraped, type(date_scraped))\n",
    "                # print(\"====\\n\")\n",
    "                \n",
    "                data = {\n",
    "                    'url': url,\n",
    "                    'author': author,\n",
    "                    'title': title,\n",
    "                    'poem': poem_data,\n",
    "                    'date_created': date_created,\n",
    "                    'rating': rating,\n",
    "                    'date_scraped': date_scraped,\n",
    "                }\n",
    "                \n",
    "                respond = supabase.table('poem_data').insert(data).execute()\n",
    "                print(f'{respond} - {poem_url} index ke-{start+idx}')\n",
    "                \n",
    "                # Pilih tidur sebentar atau lama setelah 100 batch\n",
    "                if (idx+1)%100 == 0: # \n",
    "                    durasi = round(random.uniform(60, 120)) #\n",
    "                    print(f\"Sleep checkpoint panjang selama {durasi} detik\")\n",
    "                    sleep(durasi)\n",
    "                    del durasi\n",
    "                    del divs\n",
    "                    gc.collect()\n",
    "                    i += 1\n",
    "                else: \n",
    "                    sleep(round(random.uniform(2, 5)))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Coba lagi ke-{coba+1} untuk poem {poem_url}. Error : {e}\")\n",
    "                sleep(round(random.uniform(5, 10)))\n",
    "                if coba+1 == 3:\n",
    "                    writeFile(\"fail\", f\"Scrape {poem_url} index ke-{start+idx}\", \"a\")\n",
    "        \n",
    "        # Pembersihan memori\n",
    "        driver.delete_all_cookies()\n",
    "        driver.execute_script(\"window.localStorage.clear();\")\n",
    "        driver.execute_script(\"window.sessionStorage.clear();\")\n",
    "        del url\n",
    "        gc.collect()\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "def getAllScrape(name='', custom=False, customList=[]):\n",
    "    while True:\n",
    "        with open(f\"poem_links{name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            poemsUrl = json.load(f)\n",
    "        maxLen = len(poemsUrl)\n",
    "        print(maxLen)\n",
    "        \n",
    "        files = os.listdir(f\"./poem{name}\")\n",
    "        numberFiles = [int(csvFile.split('_')[-1].split('.')[0]) for csvFile in files if csvFile.endswith(\"csv\")]\n",
    "        if len(numberFiles)==0: numberFiles = [0]\n",
    "        \n",
    "        del poemsUrl\n",
    "        del files\n",
    "        gc.collect()\n",
    "        try:\n",
    "            if maxLen == max(numberFiles)*100:\n",
    "                break\n",
    "            print(f\"i={max(numberFiles)+1}, start={max(numberFiles)*100}\")\n",
    "            scrapePoem(name, i=max(numberFiles)+1, start=max(numberFiles)*100, custom=custom, customLists=customList)\n",
    "            print(\"Done\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if maxLen == max(numberFiles)*100:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPoemLink(maxPage=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       11000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 86.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('poem_links.json')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape /poem/phenomenal-woman/ index ke-0\n",
      "data=[{'id': 3, 'url': 'https://www.poemhunter.com/poem/phenomenal-woman/', 'author': 'Maya Angelou', 'poem': \"Pretty women wonder where my secret lies.\\nI'm not cute or built to suit a fashion model's size\\nBut when I start to tell them,\\nThey think I'm telling lies.\\nI say,\\nIt's in the reach of my arms\\nThe span of my hips,\\nThe stride of my step,\\nThe curl of my lips.\\nI'm a woman\\nPhenomenally.\\nPhenomenal woman,\\nThat's me.\\n\\nI walk into a room\\nJust as cool as you please,\\nAnd to a man,\\nThe fellows stand or\\nFall down on their knees.\\nThen they swarm around me,\\nA hive of honey bees.\\nI say,\\nIt's the fire in my eyes,\\nAnd the flash of my teeth,\\nThe swing in my waist,\\nAnd the joy in my feet.\\nI'm a woman\\nPhenomenally.\\nPhenomenal woman,\\nThat's me.\\n\\nMen themselves have wondered\\nWhat they see in me.\\nThey try so much\\nBut they can't touch\\nMy inner mystery.\\nWhen I try to show them\\nThey say they still can't see.\\nI say,\\nIt's in the arch of my back,\\nThe sun of my smile,\\nThe ride of my breasts,\\nThe grace of my style.\\nI'm a woman\\n\\nPhenomenally.\\nPhenomenal woman,\\nThat's me.\\n\\nNow you understand\\nJust why my head's not bowed.\\nI don't shout or jump about\\nOr have to talk real loud.\\nWhen you see me passing\\nIt ought to make you proud.\\nI say,\\nIt's in the click of my heels,\\nThe bend of my hair,\\nthe palm of my hand,\\nThe need of my care,\\n'Cause I'm a woman\\nPhenomenally.\\nPhenomenal woman,\\nThat's me.\", 'date_created': '2003-01-03', 'rating': '4.2', 'date_scraped': '2025-05-30', 'title': 'Phenomenal Woman'}] count=None - /poem/phenomenal-woman/ index ke-0\n",
      "Scrape /poem/still-i-rise/ index ke-1\n",
      "data=[{'id': 4, 'url': 'https://www.poemhunter.com/poem/still-i-rise/', 'author': 'Maya Angelou', 'poem': \"You may write me down in history\\nWith your bitter, twisted lies,\\nYou may tread me in the very dirt\\nBut still, like dust, I'll rise.\\n\\nDoes my sassiness upset you?\\nWhy are you beset with gloom?\\n'Cause I walk like I've got oil wells\\nPumping in my living room.\\n\\nJust like moons and like suns,\\nWith the certainty of tides,\\nJust like hopes springing high,\\nStill I'll rise.\\n\\nDid you want to see me broken?\\nBowed head and lowered eyes?\\nShoulders falling down like teardrops.\\nWeakened by my soulful cries.\\n\\nDoes my haughtiness offend you?\\nDon't you take it awful hard\\n'Cause I laugh like I've got gold mines\\nDiggin' in my own back yard.\\n\\nYou may shoot me with your words,\\nYou may cut me with your eyes,\\nYou may kill me with your hatefulness,\\nBut still, like air, I'll rise.\\n\\nDoes my sexiness upset you?\\nDoes it come as a surprise\\nThat I dance like I've got diamonds\\nAt the meeting of my thighs?\\n\\nOut of the huts of history's shame\\nI rise\\nUp from a past that's rooted in pain\\nI rise\\nI'm a black ocean, leaping and wide,\\nWelling and swelling I bear in the tide.\\nLeaving behind nights of terror and fear\\nI rise\\nInto a daybreak that's wondrously clear\\nI rise\\nBringing the gifts that my ancestors gave,\\nI am the dream and the hope of the slave.\\nI rise\\nI rise\\nI rise.\", 'date_created': '2003-01-03', 'rating': '4.4', 'date_scraped': '2025-05-30', 'title': 'Still I Rise'}] count=None - /poem/still-i-rise/ index ke-1\n",
      "Scrape /poem/if-you-forget-me/ index ke-2\n",
      "data=[{'id': 5, 'url': 'https://www.poemhunter.com/poem/if-you-forget-me/', 'author': 'Pablo Neruda', 'poem': 'I want you to know\\none thing.\\n\\nYou know how this is:\\nif I look\\nat the crystal moon, at the red branch\\nof the slow autumn at my window,\\nif I touch\\nnear the fire\\nthe impalpable ash\\nor the wrinkled body of the log,\\neverything carries me to you,\\nas if everything that exists,\\naromas, light, metals,\\nwere little boats\\nthat sail\\ntoward those isles of yours that wait for me.\\n\\nWell, now,\\nif little by little you stop loving me\\nI shall stop loving you little by little.\\n\\nIf suddenly\\nyou forget me\\ndo not look for me,\\nfor I shall already have forgotten you.\\n\\nIf you think it long and mad,\\nthe wind of banners\\nthat passes through my life,\\nand you decide\\nto leave me at the shore\\nof the heart where I have roots,\\nremember\\nthat on that day,\\nat that hour,\\nI shall lift my arms\\nand my roots will set off\\nto seek another land.\\n\\nBut\\nif each day,\\neach hour,\\nyou feel that you are destined for me\\nwith implacable sweetness,\\nif each day a flower\\nclimbs up to your lips to seek me,\\nah my love, ah my own,\\nin me all that fire is repeated,\\nin me nothing is extinguished or forgotten,\\nmy love feeds on your love, beloved,\\nand as long as you live it will be in your arms\\nwithout leaving mine.', 'date_created': '2003-01-03', 'rating': '4.3', 'date_scraped': '2025-05-30', 'title': 'If You Forget Me'}] count=None - /poem/if-you-forget-me/ index ke-2\n"
     ]
    }
   ],
   "source": [
    "scrapePoem()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MainCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
