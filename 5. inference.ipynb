{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 16:30:38.991965: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-20 16:30:39.005219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740043839.019951   34114 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740043839.025459   34114 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-20 16:30:39.044530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package words to /home/hafizh/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/hafizh/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hafizh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/hafizh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/hafizh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow.keras.models import load_model # type:ignore\n",
    "from custom_function import DicodingProject1 as DP1\n",
    "\n",
    "kelass = DP1(None, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nDeliverance is not for me in renunciation.\\n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nYou shape my bones into your hunting coat.\\n...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nI'd planned to be Heathcliff's Cathy,\\nLady ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem   actual\n",
       "0  \\nDeliverance is not for me in renunciation.\\n...      joy\n",
       "1  \\nYou shape my bones into your hunting coat.\\n...  sadness\n",
       "2  \\nI'd planned to be Heathcliff's Cathy,\\nLady ...    anger"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference poem ambil random dari Google\n",
    "\n",
    "# Target : Joy\n",
    "poem1 = '''\n",
    "Deliverance is not for me in renunciation.\n",
    "I feel the embrace of freedom in a thousand bonds of delight.\n",
    "\n",
    "Thou ever pourest for me the fresh draught of thy wine of various\n",
    "colours and fragrance, filling this earthen vessel to the brim.\n",
    "\n",
    "My world will light its hundred different lamps with thy flame\n",
    "and place them before the altar of thy temple.\n",
    "\n",
    "No, I will never shut the doors of my senses.\n",
    "The delights of sight and hearing and touch will bear thy delight.\n",
    "\n",
    "Yes, all my illusions will burn into illumination of joy,\n",
    "and all my desires ripen into fruits of love.\n",
    "'''\n",
    "\n",
    "# Target : Sadness\n",
    "poem2 = '''\n",
    "You shape my bones into your hunting coat.\n",
    "Rain slants like needles through the falling air.\n",
    "The field is vast with the old blood of leaves.\n",
    "Fire in the windows warms my eyes to sleep.\n",
    "\n",
    "Trees interlace the hills with gray patchwork.\n",
    "I feel your fingers mend my broken wings.\n",
    "Wind fades your name into a thread of smoke.\n",
    "I cry its incandescence through my dreams.\n",
    "\n",
    "We must believe that gray is beautiful,\n",
    "East still exists although its outlines dim.\n",
    "I feel the wind of dawn upon my face.\n",
    "Put your hand there, and you will feel it too.\n",
    "'''\n",
    "\n",
    "# Target : Anger\n",
    "poem3 = '''\n",
    "I'd planned to be Heathcliff's Cathy,\n",
    "Lady Brett, Nicole or Dominique or Scarlett O'Hara.\n",
    "I hadn't planned to be folding up the laundry\n",
    "In uncombed hair and last night's smudged mascara,\n",
    "An expert on buying Fritos, cleaning the cat box,\n",
    "Finding lost sneakers, playing hide and seek.\n",
    "And other things unknown to Heathcliff's\n",
    "Cathy, Scarlett, Lady Brett, and Dominique.\n",
    "Why am I never running through the heather?\n",
    "Why am I never used by Howard Roark?\n",
    "Why am I never going to Pamplona\n",
    "Instead of Philadelphia and Newark?\n",
    "How did I ever wind up with an Irving\n",
    "When what I'd always had in mind was Rhett,\n",
    "Or someone more appropriate to\n",
    "Cathy, Dominique, Nicole, or Lady Brett?\n",
    "I saw myself as heedless, heartless, headstrong,\n",
    "An untamed woman searching for her mate.\n",
    "And there he is -- with charcoal, fork, and apron,\n",
    "Prepared to broil some hot dogs on the grate.\n",
    "I haven't wrecked his life or his digestion\n",
    "With unrequited love or jealous wrath.\n",
    "He Doesn't know that secretly\n",
    "I'm Scarlett, Dominique, Nicole, or Brett, or Cathy.\n",
    "Why am I never cracking up in Zurich?\n",
    "Why am I never languishing on moors?\n",
    "Why am I never spoiled by faithful servants\n",
    "Instead of spraying ant spray on the floors?\n",
    "The tricycles are cluttering my foyer,\n",
    "The Pop Tart crumbs are sprinkled on my soul.\n",
    "And every year it's harder to be\n",
    "Cathy, Dominique, Brett, Scarlett, and Nicole.\n",
    "'''\n",
    "\n",
    "poem_df = pd.DataFrame({'poem' : [poem1, poem2, poem3], 'actual' : ['joy', 'sadness', 'anger']})\n",
    "poem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deliverance renunciation feel embrace freedom ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shape hunting coat rain like needle falling ai...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would lady brett folding laundry uncombed hair...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                poem   actual\n",
       "0  deliverance renunciation feel embrace freedom ...      joy\n",
       "1  shape hunting coat rain like needle falling ai...  sadness\n",
       "2  would lady brett folding laundry uncombed hair...    anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_poem_df = kelass.cleanInference(poem_df)\n",
    "clean_poem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['hartmann', 'savani']\n",
    "test_sets = ['0.2', '0.1']\n",
    "modes = ['gru', 'lstm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740043846.237845   34114 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Menggunakan model best_model_hartmann_0.2_gru.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740043858.757148   34233 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_hartmann_0.2_lstm.keras\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_hartmann_0.1_gru.keras\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_hartmann_0.1_lstm.keras\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_savani_0.2_gru.keras\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f10a2a9a2a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_savani_0.2_lstm.keras\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f10a1e43e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_savani_0.1_gru.keras\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n",
      "===============================\n",
      "Menggunakan model best_model_savani_0.1_lstm.keras\n",
      "Poem 1 - Actual : joy - Predicted : joy\n",
      "Poem 2 - Actual : sadness - Predicted : sadness\n",
      "Poem 3 - Actual : anger - Predicted : anger\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    for test_set in test_sets:\n",
    "        for mode in modes:\n",
    "            model = load_model(f'./model/best_model_{dataset}_{test_set}_{mode}.keras')\n",
    "            print(\"===============================\")\n",
    "            print(f\"Menggunakan model best_model_{dataset}_{test_set}_{mode}.keras\")\n",
    "            with open('5.1. log_inference_result.txt', 'a') as f:\n",
    "                f.write(\"===============================\\n\")\n",
    "                f.write(f\"Menggunakan model best_model_{dataset}_{test_set}_{mode}.keras\\n\")\n",
    "            for i, text in enumerate(clean_poem_df[['poem']].values.tolist()):\n",
    "                kelas = DP1(test_set, None, mode, None, dataset)\n",
    "                text_keras = kelas.kerasTokenizer2(text)\n",
    "                result = model.predict(text_keras, verbose=0)\n",
    "                predicted_labels = np.argmax(result, axis=1)\n",
    "                dic = DP1.getLabelEncoder(dataset)\n",
    "                print(f\"Poem {i+1} - Actual : {clean_poem_df.loc[i]['actual']} - Predicted : {dic[predicted_labels[0]]}\")\n",
    "                with open('5.1. log_inference_result.txt', 'a') as f:\n",
    "                    f.write(f\"Poem {i+1} - Actual : {clean_poem_df.loc[i]['actual']} - Predicted : {dic[predicted_labels[0]]}\\n\")\n",
    "            del model\n",
    "            gc.collect()\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MainCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
